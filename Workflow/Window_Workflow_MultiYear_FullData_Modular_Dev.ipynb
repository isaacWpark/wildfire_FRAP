{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep:\n",
    "\n",
    "* Resample all inputs see 1-Resample Input Data.ipynb\n",
    "* Rasterize fires and organize by time period see 2-RasterizeFirePolygons_OrganizeData.ipynb\n",
    "\n",
    "### Data Structure:\n",
    "Data should be structured as follows:\n",
    "\n",
    "* Independent Vars 2012-2016\n",
    "    * aet\n",
    "        * aet-201201.tif\n",
    "        * ...\n",
    "        * aet-201612.tif\n",
    "    * cwd\n",
    "        * cwd-201201.tif\n",
    "        * ...\n",
    "        * cwd-201612.tif\n",
    "    * ppt\n",
    "        * ppt-201201.tif\n",
    "        * ...\n",
    "        * ppt-201612.tif\n",
    "    * ...\n",
    "* Independent Vars 2017-2021\n",
    "    * ...\n",
    "* Dependent Var 2012-2016\n",
    "    * Fire-2012-2016\n",
    "* Dependent Var 2017-2021\n",
    "    * Fire-2017-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsraster.prep as tr\n",
    "import tsraster.random as random\n",
    "import tsraster.model as model\n",
    "import tsraster.calculate as ca\n",
    "import numpy as np\n",
    "\n",
    "import tsraster.model  as md\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from math import ceil\n",
    "from tsraster.prep import set_df_mindex\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct poisson disk mask, which masks out all pixels not selected by raster mask\n",
    "'''\n",
    "Create raster of cells to be selected (populated as ones) in a raster of background value zero\n",
    "\n",
    ":param raster_mask: name of raster mask - provides dimensions for subsample, and also masks unusable areas - \n",
    "        Remaining sample area is assumed to be contiguous\n",
    ":param outFile: path and name of output mask consisting of a rater image with values of 1 for selected pixels, \n",
    "        and 0 for all other pixels\n",
    ":param k: number of attempts to select a point around each reference point before marking it as inactive\n",
    ":param r: minimum distance (in raster cells) between selected points \n",
    ":return:  list which includes an array of all masked & unnmasked cells, and a dictionary of all selected points.\n",
    "            Also saves the a raster consisting of 0s for all non-selected points, and 1s for all selected points\n",
    "            to the outFile location.\n",
    "'''\n",
    "\n",
    "\n",
    "rasterMask = random.Poisson_Subsample(raster_mask = r\"../Data\\Examples\\buffer\\StatePoly_buf.tif\",\n",
    "                                      outFile = r\"../Data\\Examples\\diskTest.tif\",\n",
    "                                      k=50, \n",
    "                                      r=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>Campground</th>\n",
       "      <th>FireStation_Dist</th>\n",
       "      <th>Airfield_Dist</th>\n",
       "      <th>City_Bounds</th>\n",
       "      <th>NPS_Bounds</th>\n",
       "      <th>Lightning</th>\n",
       "      <th>Elev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>121</td>\n",
       "      <td>78</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-23</td>\n",
       "      <td>-66</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-38</td>\n",
       "      <td>-88</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>91</td>\n",
       "      <td>34</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_id  Campground  FireStation_Dist  Airfield_Dist  City_Bounds  \\\n",
       "0         0          -1               121             78           -1   \n",
       "1         1          -1               -23            -66           -1   \n",
       "2         2          -1                95             49           -1   \n",
       "3         3          -1               -38            -88           -1   \n",
       "4         4          -1                91             34           -1   \n",
       "\n",
       "   NPS_Bounds  Lightning  Elev  \n",
       "0          -1          0   -15  \n",
       "1          -1          0   -15  \n",
       "2          -1          0   -15  \n",
       "3          -1          0   -15  \n",
       "4          -1          0   -15  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine all data that is invariant over time into single dataFrame \n",
    "#(e.g., elevation, rate of lightning strikes, fire station locations)\n",
    "\n",
    "'''Combines set of rasters to single dataFrame based on csv that lists all desired files \n",
    "    and column names to use in dataframe for data corresponding to each raster\n",
    "    \n",
    "    :param csvPath: path to csv of filepaths (in column \"FilePath\") and desired label names for values in each raster (in column \"DataName\")\n",
    "    :param outPath: path to ouput file name and location\n",
    "    :return: dataFrame consisting of all desired data with previously selected labels.\n",
    " '''\n",
    "\n",
    "invar_Data = tr.multi_image_to_dataframe(\"C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Invar_FileList.csv\", \"C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/\")\n",
    "invar_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1980_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1980_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1981_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1981_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1982_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1982_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1983_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1983_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1984_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1984_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1985_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1985_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1986_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1986_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1987_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1987_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1988_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1988_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1989_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1989_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1990_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1990_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1991_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1991_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1992_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1992_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1993_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1993_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1994_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1994_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1995_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1995_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1996_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1996_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1997_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1997_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1998_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1998_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1999_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features1999_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2000_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2000_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2001_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2001_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2002_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2002_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2003_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2003_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2004_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2004_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2005_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2005_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2006_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2006_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2007_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2007_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2008_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2008_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2009_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2009_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2010_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2010_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2011_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2011_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:08<00:00, 14.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2012_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2012_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:07<00:00, 13.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2013_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2013_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2014_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2014_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2015_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2015_3_prev_offset0.tiff\n",
      "df: C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/my_df.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 5/5 [01:06<00:00, 13.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2016_3_prev_offset0.csv\n",
      "tif:C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/extracted_features2016_3_prev_offset0.tiff\n"
     ]
    }
   ],
   "source": [
    "#conduct climate feature extraction across all years of interest\n",
    "\n",
    "\n",
    "'''\n",
    "Extracts summary statistics(features) from multiYear datasets within moving window, across years\n",
    "Outputs a series of annual dataFrames as CSV files\n",
    "\n",
    ":param startYear: year on which to start feature extraction\n",
    ":param endYear: year on which to end feature extraction\n",
    ":param featureData_Path: file path to data from which to extract features\n",
    ":param feature_params: summary statistics(features) to extract from data within each window\n",
    ":param invar_Data: year-invariate data to join with extracted feature data on an annual scale\n",
    ":param out_Path: file path to location at which extracted features should be output as a csv\n",
    ":param window_length: length of window within which to extract features\n",
    ":param window_offset: number of years by which features pertaining to each year are offset from that year\n",
    ":param mask:  mask to apply to data prior to feature extraction\n",
    ":return: no return.  instead, feature data relative to each year of interest is saved as a .csv file at the out_Path location\n",
    "          under the filename FD_Window_XXXX.csv \n",
    "'''\n",
    "ca.multiYear_Window_Extraction(1980, 2016, \"C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Climate/BCM HIST Final 1000m_1950_2016/\",\n",
    "                    feature_params = {\"mean\": None,\"maximum\": None}, \n",
    "                    invar_Data = invar_Data,\n",
    "                    out_Path = 'C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/',\n",
    "                        mask = \"C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Examples/buffer/StatePoly_buf.tif\" ,\n",
    "                    window_length = 3,\n",
    "                    window_offset = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assembly of all explanatory variables into annual dataFrames\n",
    "\n",
    "'''merge additional annually repeating data into feature data, as well as time-invariant data\n",
    "    Produces annual dataFrames consisting of all explanatory variables that may be incorporated into model\n",
    "        (Consisting of features extracted from climate data in preceding years, \n",
    "        annually repeating data such as estimated housing density,\n",
    "        and time-invariant data such as rate of lightning strikes or local elevation)\n",
    "        \n",
    "    param startYear: year on which to start feature extraction\n",
    "    param endYear: year on which to end feature extraction\n",
    "    param other_Data_prefixList: list of file path and portion of filename preceding year for additional Data\n",
    "    param feature_Data_suffixList: portion of feature data file name that follows year for additional data\n",
    "    param dataNameList: list of intended data names for additional data\n",
    "    param outPath: filepath for folder in which the output will be placed\n",
    "'''\n",
    "    \n",
    "\n",
    "\n",
    "tr.annual_Data_Merge(startYear = 1980, \n",
    "                     endYear = 2016, \n",
    "                  feature_path = \"C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/\", \n",
    "                 invarData_csvPath = \"C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Invar_FileList.csv\",\n",
    "                     other_Data_prefixList = [\"C:/Users/Python3/Documents/wildfire_FRAP/Data/Actual/SERGOM_Housing/Interpolated/bhc\"],\n",
    "                 other_Data_suffixList = [\"linreg.tif\"],\n",
    "                 dataNameList = [\"Housing_Density\"],\n",
    "                 outPath = 'C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion of fire data into annual dataframes\n",
    "\n",
    "#converts annual fire raster data into annual CSV files, does some minor reformatting for downstream processing\n",
    "'''convert annual fire data rasters into annual dataFrames, export as .CSV files\n",
    "    also does some minor reformatting to prevent problems with downstream processing\n",
    "\n",
    "    \n",
    "    #param startYear: year on which to start feature extraction\n",
    "    #param endYear: year on which to end feature extraction\n",
    "    #param file_Path: path to target data files (fire data)\n",
    "    #outPath: filepath for folder in which the output will be placed: \n",
    "\n",
    "'''\n",
    "\n",
    "tr.target_Data_to_csv_multiYear(1980, 2016,\n",
    "                            \"C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Actual/Fires/Rasters/\",\n",
    "                            'C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Python3\\Anaconda3\\envs\\ts-raster\\lib\\site-packages\\numpy\\lib\\arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "#Mask All data files (combined_data and target_data) using output of Poisson Disk Masking (or other desired mask)\n",
    "\n",
    "'''masks annual datasets (combined and fire), and saves the resulting masked data files as CSV files\n",
    "    Also returns concatenated multiYear files (combined and fire) for subsequent processing - adds in 'year' as a data column\n",
    "'''\n",
    "    #param startYear: year on which to begin\n",
    "    #param endYear: year on which to end\n",
    "    #param DataLists: csv of files to pull, with the year is the index, \n",
    "    #       \"combined_Data_Filepaths\" as the column of combined data filepaths, and\n",
    "    #       \"target_Data_filePaths\" as the column of the target data(i.e. fire) filepaths.\n",
    "    #param maskFile: filepath to data file used for masking\n",
    "    #outPath: filepath for folder in which the output will be placed\n",
    "\n",
    "\n",
    "combined_Data, target_Data = tr.multiYear_Mask(1980, 2016, \n",
    "                                               'C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/', \n",
    "                                               r\"../Data\\Examples\\diskTest.tif\", \n",
    "                                               \"C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Masked/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pixel_id.1</th>\n",
       "      <th>time</th>\n",
       "      <th>aet__maximum</th>\n",
       "      <th>aet__mean</th>\n",
       "      <th>cwd__maximum</th>\n",
       "      <th>cwd__mean</th>\n",
       "      <th>Campground</th>\n",
       "      <th>FireStation_Dist</th>\n",
       "      <th>Airfield_Dist</th>\n",
       "      <th>City_Bounds</th>\n",
       "      <th>NPS_Bounds</th>\n",
       "      <th>Lightning</th>\n",
       "      <th>Elev</th>\n",
       "      <th>Housing_Density</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135537</td>\n",
       "      <td>135537</td>\n",
       "      <td>135537</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>158.951996</td>\n",
       "      <td>61.840744</td>\n",
       "      <td>37.653000</td>\n",
       "      <td>19.579527</td>\n",
       "      <td>-1</td>\n",
       "      <td>-46</td>\n",
       "      <td>-26</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135546</td>\n",
       "      <td>135546</td>\n",
       "      <td>135546</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>133.356003</td>\n",
       "      <td>43.613838</td>\n",
       "      <td>70.831200</td>\n",
       "      <td>36.842278</td>\n",
       "      <td>-1</td>\n",
       "      <td>-30</td>\n",
       "      <td>-56</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-76</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135569</td>\n",
       "      <td>135569</td>\n",
       "      <td>135569</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>158.940002</td>\n",
       "      <td>57.745651</td>\n",
       "      <td>43.958801</td>\n",
       "      <td>22.219458</td>\n",
       "      <td>-1</td>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136471</td>\n",
       "      <td>136471</td>\n",
       "      <td>136471</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>77.573128</td>\n",
       "      <td>28.880606</td>\n",
       "      <td>96.156876</td>\n",
       "      <td>51.681374</td>\n",
       "      <td>-1</td>\n",
       "      <td>-19</td>\n",
       "      <td>111</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136495</td>\n",
       "      <td>136495</td>\n",
       "      <td>136495</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>80.501877</td>\n",
       "      <td>25.742798</td>\n",
       "      <td>112.515625</td>\n",
       "      <td>53.565712</td>\n",
       "      <td>-1</td>\n",
       "      <td>-78</td>\n",
       "      <td>-60</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_id  Unnamed: 0  pixel_id.1           time  aet__maximum  aet__mean  \\\n",
       "0    135537      135537      135537  197801_198012    158.951996  61.840744   \n",
       "1    135546      135546      135546  197801_198012    133.356003  43.613838   \n",
       "2    135569      135569      135569  197801_198012    158.940002  57.745651   \n",
       "3    136471      136471      136471  197801_198012     77.573128  28.880606   \n",
       "4    136495      136495      136495  197801_198012     80.501877  25.742798   \n",
       "\n",
       "   cwd__maximum  cwd__mean  Campground  FireStation_Dist  Airfield_Dist  \\\n",
       "0     37.653000  19.579527          -1               -46            -26   \n",
       "1     70.831200  36.842278          -1               -30            -56   \n",
       "2     43.958801  22.219458          -1                55             15   \n",
       "3     96.156876  51.681374          -1               -19            111   \n",
       "4    112.515625  53.565712          -1               -78            -60   \n",
       "\n",
       "   City_Bounds  NPS_Bounds  Lightning  Elev  Housing_Density  year  \n",
       "0           -1          -1          0    91                0  1980  \n",
       "1           -1          -1          0   -76                0  1980  \n",
       "2           -1          -1          0   111                0  1980  \n",
       "3           -1          -1          0    80                1  1980  \n",
       "4           -1          -1          0   114                0  1980  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#temporary for testing only - read in combined & target data \n",
    "\n",
    "combined_Data = pd.read_csv('C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Masked/CD_1980_Masked_2016.csv')\n",
    "target_Data = pd.read_csv('C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Masked/TD_1980_Masked_2016.csv')\n",
    "combined_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixels_Years MSE Overall:  -0.0018551728711920419\n",
      "pixels_Years R2 Overall:  -5.906211415448967e+33\n",
      "\n",
      "\n",
      "pixels MSE Overall:  -2.8369024608413766e-05\n",
      "pixels R2 Overall:  -3.822225994118679e+33\n",
      "\n",
      "\n",
      "years MSE Overall:  -0.0015050008750612206\n",
      "years R2 Overall:  -5.0859928587413605e+33\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Conduct elastic net regularization\n",
    "\n",
    "'''Conduct elastic net regressions on data, with k-fold cross-validation conducted independently \n",
    "      across both years and pixels. \n",
    "      Returns mean model MSE and R2 when predicting fire risk at \n",
    "      A) locations outside of the training dataset\n",
    "      B) years outside of the training dataset\n",
    "      C) locations and years outside of the training dataset\n",
    "    Returns a list of objects, consisting of:\n",
    "    0: Combined_Data file with testing/training groups labeled\n",
    "    1: Target Data file with testing/training groups labeled\n",
    "    2: summary dataFrame of MSE and R2 for each model run\n",
    "        (against holdout data representing either novel locations, novel years, or both)\n",
    "    3: list of elastic net models for use in predicting Fires in further locations/years\n",
    "    4: list of list of years not used in model training for each run\n",
    "'''\n",
    "#param combined_Data: explanatory factors to be used in predicting fire risk\n",
    "#param target_Data: observed fire occurrences\n",
    "#param varsToGroupBy: list of (2) column names from combined_Data & target_Data to be used in creating randomized groups\n",
    "#    -spatial grouping variable 1st, temporal (annual) grouping variable 2nd\n",
    "#param groupVars: list of (2) desired column names for the resulting randomized groups\n",
    "#param testGroups: number of distinct groups into which data sets should be divided (for each of two variables) \n",
    "  \n",
    "\n",
    "\n",
    "CrossVal_Output = model.elasticNet_2dimTest(combined_Data, target_Data, [\"pixel_id\", \"year\"], [\"pixel_group\", \"year_group\"], \n",
    "                                            testGroups = [10, 6], \n",
    "                                            DataFields = ['aet__mean', 'cwd__maximum', 'cwd__mean', 'Campground',\n",
    "       'FireStation_Dist', 'Airfield_Dist', 'City_Bounds', 'NPS_Bounds',\n",
    "       'Lightning', 'Elev', 'Housing_Density'], outPath = 'C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pixel_id.1</th>\n",
       "      <th>time</th>\n",
       "      <th>aet__maximum</th>\n",
       "      <th>aet__mean</th>\n",
       "      <th>cwd__maximum</th>\n",
       "      <th>cwd__mean</th>\n",
       "      <th>Campground</th>\n",
       "      <th>FireStation_Dist</th>\n",
       "      <th>Airfield_Dist</th>\n",
       "      <th>City_Bounds</th>\n",
       "      <th>NPS_Bounds</th>\n",
       "      <th>Lightning</th>\n",
       "      <th>Elev</th>\n",
       "      <th>Housing_Density</th>\n",
       "      <th>year</th>\n",
       "      <th>pixel_group</th>\n",
       "      <th>year_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135537</td>\n",
       "      <td>135537</td>\n",
       "      <td>135537</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>158.951996</td>\n",
       "      <td>61.840744</td>\n",
       "      <td>37.653000</td>\n",
       "      <td>19.579527</td>\n",
       "      <td>-1</td>\n",
       "      <td>-46</td>\n",
       "      <td>-26</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135546</td>\n",
       "      <td>135546</td>\n",
       "      <td>135546</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>133.356003</td>\n",
       "      <td>43.613838</td>\n",
       "      <td>70.831200</td>\n",
       "      <td>36.842278</td>\n",
       "      <td>-1</td>\n",
       "      <td>-30</td>\n",
       "      <td>-56</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-76</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135569</td>\n",
       "      <td>135569</td>\n",
       "      <td>135569</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>158.940002</td>\n",
       "      <td>57.745651</td>\n",
       "      <td>43.958801</td>\n",
       "      <td>22.219458</td>\n",
       "      <td>-1</td>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136471</td>\n",
       "      <td>136471</td>\n",
       "      <td>136471</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>77.573128</td>\n",
       "      <td>28.880606</td>\n",
       "      <td>96.156876</td>\n",
       "      <td>51.681374</td>\n",
       "      <td>-1</td>\n",
       "      <td>-19</td>\n",
       "      <td>111</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136495</td>\n",
       "      <td>136495</td>\n",
       "      <td>136495</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>80.501877</td>\n",
       "      <td>25.742798</td>\n",
       "      <td>112.515625</td>\n",
       "      <td>53.565712</td>\n",
       "      <td>-1</td>\n",
       "      <td>-78</td>\n",
       "      <td>-60</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_id  Unnamed: 0  pixel_id.1           time  aet__maximum  aet__mean  \\\n",
       "0    135537      135537      135537  197801_198012    158.951996  61.840744   \n",
       "1    135546      135546      135546  197801_198012    133.356003  43.613838   \n",
       "2    135569      135569      135569  197801_198012    158.940002  57.745651   \n",
       "3    136471      136471      136471  197801_198012     77.573128  28.880606   \n",
       "4    136495      136495      136495  197801_198012     80.501877  25.742798   \n",
       "\n",
       "   cwd__maximum  cwd__mean  Campground  FireStation_Dist  Airfield_Dist  \\\n",
       "0     37.653000  19.579527          -1               -46            -26   \n",
       "1     70.831200  36.842278          -1               -30            -56   \n",
       "2     43.958801  22.219458          -1                55             15   \n",
       "3     96.156876  51.681374          -1               -19            111   \n",
       "4    112.515625  53.565712          -1               -78            -60   \n",
       "\n",
       "   City_Bounds  NPS_Bounds  Lightning  Elev  Housing_Density  year  \\\n",
       "0           -1          -1          0    91                0  1980   \n",
       "1           -1          -1          0   -76                0  1980   \n",
       "2           -1          -1          0   111                0  1980   \n",
       "3           -1          -1          0    80                1  1980   \n",
       "4           -1          -1          0   114                0  1980   \n",
       "\n",
       "   pixel_group  year_group  \n",
       "0            0           4  \n",
       "1            6           4  \n",
       "2            0           4  \n",
       "3            4           4  \n",
       "4            0           4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combined_Data with groups\n",
    "CrossVal_Output[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "      <th>pixel_group</th>\n",
       "      <th>year_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135537</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135546</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135569</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136471</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136495</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_id  value  year  pixel_group  year_group\n",
       "0    135537      0  1980            0           4\n",
       "1    135546      0  1980            6           4\n",
       "2    135569      0  1980            0           4\n",
       "3    136471      0  1980            4           4\n",
       "4    136495      0  1980            0           4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target Data with groups\n",
    "CrossVal_Output[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pixels_Years_MSE</th>\n",
       "      <th>Pixels_MSE</th>\n",
       "      <th>Years_MSE</th>\n",
       "      <th>Pixels_Years_R2</th>\n",
       "      <th>Pixels_R2</th>\n",
       "      <th>Years_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-1.221876e-07</td>\n",
       "      <td>-0.001064</td>\n",
       "      <td>-5.598074e+33</td>\n",
       "      <td>-6.017387e+33</td>\n",
       "      <td>-9.288742e+32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002325</td>\n",
       "      <td>-1.882960e-05</td>\n",
       "      <td>-0.002196</td>\n",
       "      <td>-1.035310e+34</td>\n",
       "      <td>-2.039354e+34</td>\n",
       "      <td>-4.055591e+34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.006168</td>\n",
       "      <td>-3.031932e-05</td>\n",
       "      <td>-0.003425</td>\n",
       "      <td>-5.229212e+32</td>\n",
       "      <td>-6.696091e+33</td>\n",
       "      <td>-6.771315e+32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-3.067604e-06</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-7.248982e+33</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000804</td>\n",
       "      <td>-1.522698e-05</td>\n",
       "      <td>-0.001033</td>\n",
       "      <td>-3.947433e+33</td>\n",
       "      <td>-6.336866e+33</td>\n",
       "      <td>-9.345976e+32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pixels_Years_MSE    Pixels_MSE  Years_MSE  Pixels_Years_R2     Pixels_R2  \\\n",
       "0         -0.000021 -1.221876e-07  -0.001064    -5.598074e+33 -6.017387e+33   \n",
       "1         -0.002325 -1.882960e-05  -0.002196    -1.035310e+34 -2.039354e+34   \n",
       "2         -0.006168 -3.031932e-05  -0.003425    -5.229212e+32 -6.696091e+33   \n",
       "3         -0.000207 -3.067604e-06  -0.000351    -7.248982e+33  0.000000e+00   \n",
       "4         -0.000804 -1.522698e-05  -0.001033    -3.947433e+33 -6.336866e+33   \n",
       "\n",
       "       Years_R2  \n",
       "0 -9.288742e+32  \n",
       "1 -4.055591e+34  \n",
       "2 -6.771315e+32  \n",
       "3  0.000000e+00  \n",
       "4 -9.345976e+32  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary MSE and R2 for all runs, against spatially novel, temporally novel, and completely novel data\n",
    "CrossVal_Output[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -2.063837421450998e-05,\n",
       "  -5.598074342713791e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0023249380679646325,\n",
       "  -1.0353097934196502e+34),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.006167807380779378,\n",
       "  -5.229211512509413e+32),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.00020711274600704321,\n",
       "  -7.24898219483152e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0008040012856145307,\n",
       "  -3.947432977508544e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0002521045181833603,\n",
       "  -2.8423987980676924e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.000850897887355595,\n",
       "  -9.859805801997714e+32),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.001230332486977126,\n",
       "  -3.393758515592727e+34),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.007860029130086543,\n",
       "  -1.8842097172894046e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0014703268390576785,\n",
       "  -3.3248181066041936e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.002585530691956661,\n",
       "  -2.91336930358029e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.002074001298816963,\n",
       "  -1.0458102469725307e+34),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0006055309573598233,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0025599672530229878,\n",
       "  -1.0756319675122348e+34),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0028558536435763227,\n",
       "  -2.914154823184545e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -6.9767906460960205e-06,\n",
       "  -5.592763833909742e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.000347446727623657,\n",
       "  -4.562200490843426e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0005574379798296558,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0030703244553933473,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0022627571841047356,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.00961854329865286,\n",
       "  -1.679613423525096e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -3.4492168749622465e-05,\n",
       "  -5.391660948688174e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.003813211297839958,\n",
       "  -2.5033619297684842e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0013268262004786369,\n",
       "  -3.6206102886696155e+34),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.00021335250561560493,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0036304161153004606,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.00495357003353547,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -1.1290496249038995e-07,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0007699544864636643,\n",
       "  -3.943603357718596e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0010557740365377821,\n",
       "  -3.704919469599272e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0005070281751851091,\n",
       "  -4.356206419834244e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.002242023801433124,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0030118394708142926,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.004206730381714596,\n",
       "  -2.2938561450368596e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.002600196101697927,\n",
       "  -2.913411919150987e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0008851625452219736,\n",
       "  -8.158416289070617e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0013091007867092053,\n",
       "  -3.5348066037320114e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0015850217461699234,\n",
       "  -9.112624578480297e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0019770803503336154,\n",
       "  -3.329619051148705e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0011312504575324844,\n",
       "  -3.53417875912583e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.00026130085795927904,\n",
       "  -4.7728789651261893e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0011682157905212875,\n",
       "  -8.697537394335956e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.001281544920391564,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0016026474495935972,\n",
       "  -3.641715065106508e+34),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0019422210914423754,\n",
       "  -3.32638476565807e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0006672565684167076,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0010464059921049262,\n",
       "  -3.7376639032358724e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.002127985966385415,\n",
       "  -4.183466351360084e+34),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0007976499523416614,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0031787838075301167,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0015828779156648043,\n",
       "  -3.5324619690467307e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.00017575952737325373,\n",
       "  -1.1920014469856174e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0016348333708939844,\n",
       "  -3.32536425787902e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0005507944065803461,\n",
       "  -7.27410831515782e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0038039770104616455,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0014347819278952567,\n",
       "  -8.897282671041443e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.004411574211039548,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -7.713952703425342e-05,\n",
       "  -5.1804761663809785e+33),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.0001959517735701244,\n",
       "  0.0),\n",
       " (ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  -0.00038296764080292256,\n",
       "  -2.767991757089368e+34)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List of models\n",
    "CrossVal_Output[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1986, 1988, 1991, 1997, 2004, 2012],\n",
       " [2016, 1990, 2000, 2003, 2007, 2008],\n",
       " [1984, 1994, 1998, 2010, 2011, 1981],\n",
       " [1985, 1992, 2005, 2014, 2009, 1982],\n",
       " [1995, 2001, 2002, 1980, 2013, 1983],\n",
       " [1987, 1989, 1993, 1996, 1999, 2006, 2015],\n",
       " [1986, 1988, 1991, 1997, 2004, 2012],\n",
       " [2016, 1990, 2000, 2003, 2007, 2008],\n",
       " [1984, 1994, 1998, 2010, 2011, 1981],\n",
       " [1985, 1992, 2005, 2014, 2009, 1982],\n",
       " [1995, 2001, 2002, 1980, 2013, 1983],\n",
       " [1987, 1989, 1993, 1996, 1999, 2006, 2015],\n",
       " [1986, 1988, 1991, 1997, 2004, 2012],\n",
       " [2016, 1990, 2000, 2003, 2007, 2008],\n",
       " [1984, 1994, 1998, 2010, 2011, 1981],\n",
       " [1985, 1992, 2005, 2014, 2009, 1982],\n",
       " [1995, 2001, 2002, 1980, 2013, 1983],\n",
       " [1987, 1989, 1993, 1996, 1999, 2006, 2015],\n",
       " [1986, 1988, 1991, 1997, 2004, 2012],\n",
       " [2016, 1990, 2000, 2003, 2007, 2008],\n",
       " [1984, 1994, 1998, 2010, 2011, 1981],\n",
       " [1985, 1992, 2005, 2014, 2009, 1982],\n",
       " [1995, 2001, 2002, 1980, 2013, 1983],\n",
       " [1987, 1989, 1993, 1996, 1999, 2006, 2015],\n",
       " [1986, 1988, 1991, 1997, 2004, 2012],\n",
       " [2016, 1990, 2000, 2003, 2007, 2008],\n",
       " [1984, 1994, 1998, 2010, 2011, 1981],\n",
       " [1985, 1992, 2005, 2014, 2009, 1982],\n",
       " [1995, 2001, 2002, 1980, 2013, 1983],\n",
       " [1987, 1989, 1993, 1996, 1999, 2006, 2015],\n",
       " [1986, 1988, 1991, 1997, 2004, 2012],\n",
       " [2016, 1990, 2000, 2003, 2007, 2008],\n",
       " [1984, 1994, 1998, 2010, 2011, 1981],\n",
       " [1985, 1992, 2005, 2014, 2009, 1982],\n",
       " [1995, 2001, 2002, 1980, 2013, 1983],\n",
       " [1987, 1989, 1993, 1996, 1999, 2006, 2015],\n",
       " [1986, 1988, 1991, 1997, 2004, 2012],\n",
       " [2016, 1990, 2000, 2003, 2007, 2008],\n",
       " [1984, 1994, 1998, 2010, 2011, 1981],\n",
       " [1985, 1992, 2005, 2014, 2009, 1982],\n",
       " [1995, 2001, 2002, 1980, 2013, 1983],\n",
       " [1987, 1989, 1993, 1996, 1999, 2006, 2015],\n",
       " [1986, 1988, 1991, 1997, 2004, 2012],\n",
       " [2016, 1990, 2000, 2003, 2007, 2008],\n",
       " [1984, 1994, 1998, 2010, 2011, 1981],\n",
       " [1985, 1992, 2005, 2014, 2009, 1982],\n",
       " [1995, 2001, 2002, 1980, 2013, 1983],\n",
       " [1987, 1989, 1993, 1996, 1999, 2006, 2015],\n",
       " [1986, 1988, 1991, 1997, 2004, 2012],\n",
       " [2016, 1990, 2000, 2003, 2007, 2008],\n",
       " [1984, 1994, 1998, 2010, 2011, 1981],\n",
       " [1985, 1992, 2005, 2014, 2009, 1982],\n",
       " [1995, 2001, 2002, 1980, 2013, 1983],\n",
       " [1987, 1989, 1993, 1996, 1999, 2006, 2015],\n",
       " [1986, 1988, 1991, 1997, 2004, 2012],\n",
       " [2016, 1990, 2000, 2003, 2007, 2008],\n",
       " [1984, 1994, 1998, 2010, 2011, 1981],\n",
       " [1985, 1992, 2005, 2014, 2009, 1982],\n",
       " [1995, 2001, 2002, 1980, 2013, 1983],\n",
       " [1987, 1989, 1993, 1996, 1999, 2006, 2015]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of years excluded from training data for each model run\n",
    "CrossVal_Output[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pixel_id.1</th>\n",
       "      <th>time</th>\n",
       "      <th>aet__maximum</th>\n",
       "      <th>aet__mean</th>\n",
       "      <th>cwd__maximum</th>\n",
       "      <th>cwd__mean</th>\n",
       "      <th>Campground</th>\n",
       "      <th>FireStation_Dist</th>\n",
       "      <th>Airfield_Dist</th>\n",
       "      <th>City_Bounds</th>\n",
       "      <th>NPS_Bounds</th>\n",
       "      <th>Lightning</th>\n",
       "      <th>Elev</th>\n",
       "      <th>Housing_Density</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135537</td>\n",
       "      <td>135537</td>\n",
       "      <td>135537</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>158.951996</td>\n",
       "      <td>61.840744</td>\n",
       "      <td>37.653000</td>\n",
       "      <td>19.579527</td>\n",
       "      <td>-1</td>\n",
       "      <td>-46</td>\n",
       "      <td>-26</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135546</td>\n",
       "      <td>135546</td>\n",
       "      <td>135546</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>133.356003</td>\n",
       "      <td>43.613838</td>\n",
       "      <td>70.831200</td>\n",
       "      <td>36.842278</td>\n",
       "      <td>-1</td>\n",
       "      <td>-30</td>\n",
       "      <td>-56</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-76</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135569</td>\n",
       "      <td>135569</td>\n",
       "      <td>135569</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>158.940002</td>\n",
       "      <td>57.745651</td>\n",
       "      <td>43.958801</td>\n",
       "      <td>22.219458</td>\n",
       "      <td>-1</td>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136471</td>\n",
       "      <td>136471</td>\n",
       "      <td>136471</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>77.573128</td>\n",
       "      <td>28.880606</td>\n",
       "      <td>96.156876</td>\n",
       "      <td>51.681374</td>\n",
       "      <td>-1</td>\n",
       "      <td>-19</td>\n",
       "      <td>111</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136495</td>\n",
       "      <td>136495</td>\n",
       "      <td>136495</td>\n",
       "      <td>197801_198012</td>\n",
       "      <td>80.501877</td>\n",
       "      <td>25.742798</td>\n",
       "      <td>112.515625</td>\n",
       "      <td>53.565712</td>\n",
       "      <td>-1</td>\n",
       "      <td>-78</td>\n",
       "      <td>-60</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_id  Unnamed: 0  pixel_id.1           time  aet__maximum  aet__mean  \\\n",
       "0    135537      135537      135537  197801_198012    158.951996  61.840744   \n",
       "1    135546      135546      135546  197801_198012    133.356003  43.613838   \n",
       "2    135569      135569      135569  197801_198012    158.940002  57.745651   \n",
       "3    136471      136471      136471  197801_198012     77.573128  28.880606   \n",
       "4    136495      136495      136495  197801_198012     80.501877  25.742798   \n",
       "\n",
       "   cwd__maximum  cwd__mean  Campground  FireStation_Dist  Airfield_Dist  \\\n",
       "0     37.653000  19.579527          -1               -46            -26   \n",
       "1     70.831200  36.842278          -1               -30            -56   \n",
       "2     43.958801  22.219458          -1                55             15   \n",
       "3     96.156876  51.681374          -1               -19            111   \n",
       "4    112.515625  53.565712          -1               -78            -60   \n",
       "\n",
       "   City_Bounds  NPS_Bounds  Lightning  Elev  Housing_Density  year  \n",
       "0           -1          -1          0    91                0  1980  \n",
       "1           -1          -1          0   -76                0  1980  \n",
       "2           -1          -1          0   111                0  1980  \n",
       "3           -1          -1          0    80                1  1980  \n",
       "4           -1          -1          0   114                0  1980  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = model.elastic_YearPredictor(combined_Data, target_Data, \n",
    "                  preMasked_Data_Path = \"C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Pre_Masked/\",\n",
    "                  outPath = \"C:/Users/Python3/Documents/wildfire_FRAP_working/wildfire_FRAP/Data/Extracted_Features/Test_Preds/\",  \n",
    "                  year_List = [1980, 1981, 1982, 1983], \n",
    "                  DataFields = ['aet__mean', 'cwd__maximum', 'cwd__mean', 'Campground',\n",
    "       'FireStation_Dist', 'Airfield_Dist', 'City_Bounds', 'NPS_Bounds',\n",
    "       'Lightning', 'Elev', 'Housing_Density'],\n",
    "                 mask = r\"../Data/Examples/buffer/StatePoly_buf.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False)],\n",
       " [ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False)],\n",
       " [ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False)],\n",
       " [ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "        max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "        random_state=None, selection='cyclic', tol=0.0001, warm_start=False)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1980, 1981, 1982, 1983]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
